"""
æ–‡ä»¶æ“ä½œå·¥å…·
æä¾›å®‰å…¨çš„æ–‡ä»¶è¯»å†™åŠŸèƒ½
"""

import os
import json
import csv
from pathlib import Path
from typing import Dict, Any, List, Union, Optional
from langchain.tools import BaseTool
from pydantic import Field
from loguru import logger

from config import get_config


class SafeFileHandler:
    """å®‰å…¨æ–‡ä»¶å¤„ç†å™¨"""
    
    def __init__(self):
        self.config = get_config()
        self.base_dir = Path(self.config.tools.file_base_directory)
        self.max_file_size = self.config.tools.file_max_size
        self.allowed_extensions = self.config.tools.file_allowed_extensions
        
        # ç¡®ä¿åŸºç¡€ç›®å½•å­˜åœ¨
        self.base_dir.mkdir(parents=True, exist_ok=True)
        
        logger.info(f"æ–‡ä»¶å¤„ç†å™¨åˆå§‹åŒ– - åŸºç¡€ç›®å½•: {self.base_dir}, æœ€å¤§æ–‡ä»¶å¤§å°: {self.max_file_size} bytes")
    
    def _validate_path(self, file_path: str) -> Path:
        """
        éªŒè¯æ–‡ä»¶è·¯å¾„å®‰å…¨æ€§
        
        Args:
            file_path: æ–‡ä»¶è·¯å¾„
            
        Returns:
            éªŒè¯åçš„Pathå¯¹è±¡
            
        Raises:
            ValueError: è·¯å¾„ä¸å®‰å…¨æˆ–ä¸å…è®¸
        """
        # è½¬æ¢ä¸ºPathå¯¹è±¡
        path = Path(file_path)
        
        # å¦‚æœæ˜¯ç›¸å¯¹è·¯å¾„ï¼Œç›¸å¯¹äºåŸºç¡€ç›®å½•
        if not path.is_absolute():
            path = self.base_dir / path
        
        # è§£æçœŸå®è·¯å¾„ï¼Œé˜²æ­¢ç›®å½•éå†æ”»å‡»
        try:
            resolved_path = path.resolve()
        except Exception as e:
            raise ValueError(f"è·¯å¾„è§£æå¤±è´¥: {e}")
        
        # æ£€æŸ¥æ˜¯å¦åœ¨å…è®¸çš„åŸºç¡€ç›®å½•å†…
        try:
            resolved_path.relative_to(self.base_dir.resolve())
        except ValueError:
            raise ValueError(f"è·¯å¾„ä¸åœ¨å…è®¸çš„ç›®å½•å†…: {resolved_path}")
        
        return resolved_path
    
    def _validate_extension(self, file_path: Path) -> None:
        """
        éªŒè¯æ–‡ä»¶æ‰©å±•å
        
        Args:
            file_path: æ–‡ä»¶è·¯å¾„
            
        Raises:
            ValueError: æ‰©å±•åä¸è¢«å…è®¸
        """
        extension = file_path.suffix.lower()
        if extension not in self.allowed_extensions:
            raise ValueError(f"æ–‡ä»¶æ‰©å±•å '{extension}' ä¸è¢«å…è®¸ã€‚å…è®¸çš„æ‰©å±•å: {', '.join(self.allowed_extensions)}")
    
    def _validate_file_size(self, file_path: Path) -> None:
        """
        éªŒè¯æ–‡ä»¶å¤§å°
        
        Args:
            file_path: æ–‡ä»¶è·¯å¾„
            
        Raises:
            ValueError: æ–‡ä»¶è¿‡å¤§
        """
        if file_path.exists():
            file_size = file_path.stat().st_size
            if file_size > self.max_file_size:
                raise ValueError(f"æ–‡ä»¶è¿‡å¤§: {file_size} bytesï¼Œæœ€å¤§å…è®¸: {self.max_file_size} bytes")


class FileReadTool(BaseTool):
    """æ–‡ä»¶è¯»å–å·¥å…·"""
    
    name: str = "read_file"
    description: str = """
    è¯»å–æ–‡ä»¶å†…å®¹çš„å·¥å…·ã€‚æ”¯æŒæ–‡æœ¬æ–‡ä»¶ã€JSONæ–‡ä»¶ã€CSVæ–‡ä»¶ç­‰ã€‚
    
    è¾“å…¥å‚æ•°: æ–‡ä»¶è·¯å¾„ï¼ˆç›¸å¯¹äºæ•°æ®ç›®å½•æˆ–ç»å¯¹è·¯å¾„ï¼‰
    æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: .txt, .md, .json, .csv
    
    ç¤ºä¾‹:
    - data.txt
    - notes/readme.md
    - config.json
    - reports/sales.csv
    """
    
    def __init__(self):
        super().__init__()
        self.handler = SafeFileHandler()
    
    def _run(self, file_path: str) -> str:
        """
        è¯»å–æ–‡ä»¶å†…å®¹
        
        Args:
            file_path: æ–‡ä»¶è·¯å¾„
            
        Returns:
            æ–‡ä»¶å†…å®¹å­—ç¬¦ä¸²
        """
        logger.info(f"è¯»å–æ–‡ä»¶: {file_path}")
        
        try:
            # éªŒè¯è·¯å¾„
            path = self.handler._validate_path(file_path)
            self.handler._validate_extension(path)
            
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not path.exists():
                return f"é”™è¯¯: æ–‡ä»¶ä¸å­˜åœ¨ - {path}"
            
            if not path.is_file():
                return f"é”™è¯¯: è·¯å¾„ä¸æ˜¯æ–‡ä»¶ - {path}"
            
            # éªŒè¯æ–‡ä»¶å¤§å°
            self.handler._validate_file_size(path)
            
            # æ ¹æ®æ–‡ä»¶ç±»å‹è¯»å–
            extension = path.suffix.lower()
            
            if extension == '.json':
                return self._read_json_file(path)
            elif extension == '.csv':
                return self._read_csv_file(path)
            else:
                return self._read_text_file(path)
                
        except Exception as e:
            logger.error(f"è¯»å–æ–‡ä»¶å¤±è´¥: {e}")
            return f"è¯»å–æ–‡ä»¶å¤±è´¥: {str(e)}"
    
    def _read_text_file(self, path: Path) -> str:
        """è¯»å–æ–‡æœ¬æ–‡ä»¶"""
        try:
            with open(path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            logger.info(f"æˆåŠŸè¯»å–æ–‡æœ¬æ–‡ä»¶: {path} ({len(content)} å­—ç¬¦)")
            return f"æ–‡ä»¶å†…å®¹ ({path.name}):\\n\\n{content}"
            
        except UnicodeDecodeError:
            # å°è¯•å…¶ä»–ç¼–ç 
            for encoding in ['gbk', 'latin-1']:
                try:
                    with open(path, 'r', encoding=encoding) as f:
                        content = f.read()
                    logger.info(f"ä½¿ç”¨ {encoding} ç¼–ç è¯»å–æ–‡ä»¶: {path}")
                    return f"æ–‡ä»¶å†…å®¹ ({path.name}, ç¼–ç : {encoding}):\\n\\n{content}"
                except UnicodeDecodeError:
                    continue
            
            raise ValueError(f"æ— æ³•è§£ç æ–‡ä»¶ï¼Œå°è¯•äº†å¤šç§ç¼–ç æ ¼å¼")
    
    def _read_json_file(self, path: Path) -> str:
        """è¯»å–JSONæ–‡ä»¶"""
        with open(path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        # æ ¼å¼åŒ–JSONè¾“å‡º
        formatted_json = json.dumps(data, ensure_ascii=False, indent=2)
        logger.info(f"æˆåŠŸè¯»å–JSONæ–‡ä»¶: {path}")
        
        return f"JSONæ–‡ä»¶å†…å®¹ ({path.name}):\\n\\n{formatted_json}"
    
    def _read_csv_file(self, path: Path) -> str:
        """è¯»å–CSVæ–‡ä»¶"""
        rows = []
        with open(path, 'r', encoding='utf-8') as f:
            csv_reader = csv.reader(f)
            for i, row in enumerate(csv_reader):
                rows.append(row)
                # é™åˆ¶è¯»å–è¡Œæ•°ï¼Œé¿å…è¾“å‡ºè¿‡é•¿
                if i >= 50:
                    rows.append([f"... (çœç•¥å‰©ä½™ {sum(1 for _ in csv.reader(open(path, 'r', encoding='utf-8'))) - 51} è¡Œ)"])
                    break
        
        # æ ¼å¼åŒ–CSVè¾“å‡º
        formatted_rows = []
        for row in rows:
            formatted_rows.append(" | ".join(str(cell) for cell in row))
        
        logger.info(f"æˆåŠŸè¯»å–CSVæ–‡ä»¶: {path} ({len(rows)} è¡Œ)")
        return f"CSVæ–‡ä»¶å†…å®¹ ({path.name}):\\n\\n" + "\\n".join(formatted_rows)
    
    async def _arun(self, file_path: str) -> str:
        """å¼‚æ­¥è¿è¡Œ"""
        return self._run(file_path)


class FileWriteTool(BaseTool):
    """æ–‡ä»¶å†™å…¥å·¥å…·"""
    
    name: str = "write_file"
    description: str = """
    å†™å…¥å†…å®¹åˆ°æ–‡ä»¶çš„å·¥å…·ã€‚æ”¯æŒåˆ›å»ºæ–°æ–‡ä»¶æˆ–è¦†ç›–ç°æœ‰æ–‡ä»¶ã€‚
    
    è¾“å…¥å‚æ•°æ ¼å¼: file_path|content
    ä½¿ç”¨ | åˆ†éš”æ–‡ä»¶è·¯å¾„å’Œå†…å®¹
    
    æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: .txt, .md, .json, .csv
    
    ç¤ºä¾‹:
    - notes.txt|è¿™æ˜¯æ–‡ä»¶å†…å®¹
    - data/config.json|{"key": "value"}
    - report.md|# æŠ¥å‘Šæ ‡é¢˜\\n\\nå†…å®¹...
    """
    
    def __init__(self):
        super().__init__()
        self.handler = SafeFileHandler()
    
    def _run(self, input_str: str) -> str:
        """
        å†™å…¥æ–‡ä»¶
        
        Args:
            input_str: "æ–‡ä»¶è·¯å¾„|æ–‡ä»¶å†…å®¹" æ ¼å¼çš„å­—ç¬¦ä¸²
            
        Returns:
            æ“ä½œç»“æœå­—ç¬¦ä¸²
        """
        logger.info("æ‰§è¡Œæ–‡ä»¶å†™å…¥æ“ä½œ")
        
        try:
            # è§£æè¾“å…¥å‚æ•°
            if '|' not in input_str:
                return "é”™è¯¯: è¾“å…¥æ ¼å¼é”™è¯¯ï¼Œè¯·ä½¿ç”¨ 'æ–‡ä»¶è·¯å¾„|æ–‡ä»¶å†…å®¹' æ ¼å¼"
            
            file_path, content = input_str.split('|', 1)
            file_path = file_path.strip()
            
            # éªŒè¯è·¯å¾„
            path = self.handler._validate_path(file_path)
            self.handler._validate_extension(path)
            
            # åˆ›å»ºçˆ¶ç›®å½•
            path.parent.mkdir(parents=True, exist_ok=True)
            
            # æ£€æŸ¥å†…å®¹é•¿åº¦
            if len(content.encode('utf-8')) > self.handler.max_file_size:
                return f"é”™è¯¯: å†…å®¹è¿‡å¤§ï¼Œæœ€å¤§å…è®¸ {self.handler.max_file_size} bytes"
            
            # æ ¹æ®æ–‡ä»¶ç±»å‹å†™å…¥
            extension = path.suffix.lower()
            
            if extension == '.json':
                return self._write_json_file(path, content)
            else:
                return self._write_text_file(path, content)
                
        except Exception as e:
            logger.error(f"å†™å…¥æ–‡ä»¶å¤±è´¥: {e}")
            return f"å†™å…¥æ–‡ä»¶å¤±è´¥: {str(e)}"
    
    def _write_text_file(self, path: Path, content: str) -> str:
        """å†™å…¥æ–‡æœ¬æ–‡ä»¶"""
        with open(path, 'w', encoding='utf-8') as f:
            f.write(content)
        
        file_size = path.stat().st_size
        logger.info(f"æˆåŠŸå†™å…¥æ–‡æœ¬æ–‡ä»¶: {path} ({file_size} bytes)")
        
        return f"æˆåŠŸå†™å…¥æ–‡ä»¶: {path.name} ({file_size} bytes)"
    
    def _write_json_file(self, path: Path, content: str) -> str:
        """å†™å…¥JSONæ–‡ä»¶"""
        try:
            # éªŒè¯JSONæ ¼å¼
            json_data = json.loads(content)
            
            # å†™å…¥æ ¼å¼åŒ–çš„JSON
            with open(path, 'w', encoding='utf-8') as f:
                json.dump(json_data, f, ensure_ascii=False, indent=2)
            
            file_size = path.stat().st_size
            logger.info(f"æˆåŠŸå†™å…¥JSONæ–‡ä»¶: {path} ({file_size} bytes)")
            
            return f"æˆåŠŸå†™å…¥JSONæ–‡ä»¶: {path.name} ({file_size} bytes)"
            
        except json.JSONDecodeError as e:
            return f"é”™è¯¯: JSONæ ¼å¼ä¸æ­£ç¡® - {str(e)}"
    
    async def _arun(self, input_str: str) -> str:
        """å¼‚æ­¥è¿è¡Œ"""
        return self._run(input_str)


class FileListTool(BaseTool):
    """æ–‡ä»¶åˆ—è¡¨å·¥å…·"""
    
    name: str = "list_files"
    description: str = """
    åˆ—å‡ºç›®å½•ä¸­çš„æ–‡ä»¶å’Œå­ç›®å½•ã€‚
    
    è¾“å…¥å‚æ•°: ç›®å½•è·¯å¾„ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä¸ºæ•°æ®ç›®å½•ï¼‰
    
    ç¤ºä¾‹:
    - ï¼ˆç©ºè¾“å…¥ï¼‰ï¼šåˆ—å‡ºæ•°æ®æ ¹ç›®å½•
    - notesï¼šåˆ—å‡ºnoteså­ç›®å½•
    - reports/2023ï¼šåˆ—å‡ºreports/2023ç›®å½•
    """
    
    def __init__(self):
        super().__init__()
        self.handler = SafeFileHandler()
    
    def _run(self, directory: str = "") -> str:
        """
        åˆ—å‡ºç›®å½•å†…å®¹
        
        Args:
            directory: ç›®å½•è·¯å¾„ï¼Œç©ºå­—ç¬¦ä¸²è¡¨ç¤ºæ ¹ç›®å½•
            
        Returns:
            ç›®å½•å†…å®¹å­—ç¬¦ä¸²
        """
        logger.info(f"åˆ—å‡ºç›®å½•å†…å®¹: {directory or 'æ ¹ç›®å½•'}")
        
        try:
            # ç¡®å®šç›®å½•è·¯å¾„
            if not directory.strip():
                path = self.handler.base_dir
            else:
                path = self.handler._validate_path(directory)
            
            # æ£€æŸ¥ç›®å½•æ˜¯å¦å­˜åœ¨
            if not path.exists():
                return f"é”™è¯¯: ç›®å½•ä¸å­˜åœ¨ - {path}"
            
            if not path.is_dir():
                return f"é”™è¯¯: è·¯å¾„ä¸æ˜¯ç›®å½• - {path}"
            
            # è·å–ç›®å½•å†…å®¹
            items = []
            total_files = 0
            total_dirs = 0
            
            for item in sorted(path.iterdir()):
                relative_path = item.relative_to(self.handler.base_dir)
                
                if item.is_dir():
                    items.append(f"ğŸ“ {relative_path}/")
                    total_dirs += 1
                else:
                    file_size = item.stat().st_size
                    size_str = self._format_file_size(file_size)
                    items.append(f"ğŸ“„ {relative_path} ({size_str})")
                    total_files += 1
            
            if not items:
                return f"ç›®å½•ä¸ºç©º: {path.relative_to(self.handler.base_dir.parent)}"
            
            header = f"ç›®å½•å†…å®¹: {path.relative_to(self.handler.base_dir.parent)} ({total_dirs} ä¸ªç›®å½•, {total_files} ä¸ªæ–‡ä»¶)"
            content = "\\n".join(items)
            
            logger.info(f"åˆ—å‡ºç›®å½•æˆåŠŸ: {total_dirs} ä¸ªç›®å½•, {total_files} ä¸ªæ–‡ä»¶")
            return f"{header}\\n\\n{content}"
            
        except Exception as e:
            logger.error(f"åˆ—å‡ºç›®å½•å¤±è´¥: {e}")
            return f"åˆ—å‡ºç›®å½•å¤±è´¥: {str(e)}"
    
    def _format_file_size(self, size_bytes: int) -> str:
        """æ ¼å¼åŒ–æ–‡ä»¶å¤§å°"""
        if size_bytes < 1024:
            return f"{size_bytes} B"
        elif size_bytes < 1024 * 1024:
            return f"{size_bytes / 1024:.1f} KB"
        else:
            return f"{size_bytes / (1024 * 1024):.1f} MB"
    
    async def _arun(self, directory: str = "") -> str:
        """å¼‚æ­¥è¿è¡Œ"""
        return self._run(directory)


def create_file_tools() -> List[BaseTool]:
    """åˆ›å»ºæ‰€æœ‰æ–‡ä»¶æ“ä½œå·¥å…·"""
    return [
        FileReadTool(),
        FileWriteTool(),
        FileListTool()
    ]


if __name__ == "__main__":
    # æµ‹è¯•æ–‡ä»¶æ“ä½œå·¥å…·
    tools = create_file_tools()
    read_tool, write_tool, list_tool = tools
    
    print("æ–‡ä»¶æ“ä½œå·¥å…·æµ‹è¯•:")
    print("=" * 50)
    
    # æµ‹è¯•å†™å…¥æ–‡ä»¶
    print("\\n1. æµ‹è¯•æ–‡ä»¶å†™å…¥:")
    result = write_tool._run("test.txt|è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•æ–‡ä»¶\\nåŒ…å«å¤šè¡Œå†…å®¹\\næµ‹è¯•å®Œæˆï¼")
    print(result)
    
    # æµ‹è¯•JSONå†™å…¥
    print("\\n2. æµ‹è¯•JSONå†™å…¥:")
    json_content = '{"name": "æµ‹è¯•", "version": "1.0", "features": ["è¯»å–", "å†™å…¥", "åˆ—è¡¨"]}'
    result = write_tool._run(f"config.json|{json_content}")
    print(result)
    
    # æµ‹è¯•ç›®å½•åˆ—è¡¨
    print("\\n3. æµ‹è¯•ç›®å½•åˆ—è¡¨:")
    result = list_tool._run("")
    print(result)
    
    # æµ‹è¯•æ–‡ä»¶è¯»å–
    print("\\n4. æµ‹è¯•æ–‡ä»¶è¯»å–:")
    result = read_tool._run("test.txt")
    print(result)
    
    print("\\n5. æµ‹è¯•JSONè¯»å–:")
    result = read_tool._run("config.json")
    print(result)
    
    # æµ‹è¯•é”™è¯¯æƒ…å†µ
    print("\\n6. æµ‹è¯•é”™è¯¯æƒ…å†µ:")
    result = read_tool._run("nonexistent.txt")
    print(result)
    
    print("\\n7. æµ‹è¯•ä¸å®‰å…¨è·¯å¾„:")
    result = read_tool._run("../../../etc/passwd")
    print(result)
    
    print("\\næ–‡ä»¶æ“ä½œå·¥å…·æµ‹è¯•å®Œæˆï¼")